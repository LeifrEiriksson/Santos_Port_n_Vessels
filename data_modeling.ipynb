{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from retry_requests import retry\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict = {\n",
    "'scheduled' : {\n",
    "'url': \"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/atracacoes-programadas/\",\n",
    "'columns':['Date','Hour','ETA','Place','Ship','IMO','Cargo','Event','Voyage','DUV'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'foreseen_cargo' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/navios-esperados-carga/\",\n",
    "'columns':['Ship','Flag','Draft','Nav','Arrival','Notice','Office','Operation','Goods','Weight','Voyage','DUV','P','Terminal','IMO'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'foreseen_cruise' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/navios-esperados-passageiros/\",\n",
    "'columns':['Ship','Flag','Draft','Nav','Arrival','Notice','Office','Voyage','DUV','P','Terminal'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'berthage_ships' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/navios-fundeados/\",\n",
    "'columns':['Ship','Flag','Draft','Nav','Arrival','Notice','Office','Operat','Type','Weight','Voyage','P','Terminal'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'berthed_ships' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/atracados-porto-terminais/\",\n",
    "'columns':['Place','Ship','Cargo','Unload','Load'],\n",
    "'df' : None\n",
    "},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Santos_Port_n_Vessels\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Santos_Port_n_Vessels\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Santos_Port_n_Vessels\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Santos_Port_n_Vessels\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Santos_Port_n_Vessels\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for key, value in infos_dict.items():\n",
    "\n",
    "    table = None\n",
    "    op = None\n",
    "\n",
    "    url = value['url']\n",
    "    columns_df = value['columns']\n",
    "    \n",
    "    data = requests.get(url, verify=False).text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "    if key != 'berthed_ships':\n",
    "        table = soup.find_all('tbody')\n",
    "\n",
    "    else:\n",
    "        table = soup.find('table', {'id':'atracados'})\n",
    "\n",
    "    df = pd.DataFrame(columns = columns_df)\n",
    "\n",
    "    for i in range(len(table)):\n",
    "\n",
    "        if key != 'berthed_ships':\n",
    "            op = table[i].find_all('tr')\n",
    "\n",
    "        else:\n",
    "            op = table.tbody.find_all('tr')\n",
    "\n",
    "        for row in op:\n",
    "\n",
    "            columns = row.find_all('td')\n",
    "\n",
    "            if(columns != []):\n",
    "\n",
    "                dict_merge = {}\n",
    "\n",
    "                for j in range(len(columns_df)):\n",
    "\n",
    "                    if key != 'berthed_ships':\n",
    "\n",
    "                        row = {\n",
    "                            columns_df[j]: columns[j].text.strip()\n",
    "                        }\n",
    "                    \n",
    "                    else:\n",
    "                                                \n",
    "                        columns_index = (0,1,6,7,8)\n",
    "\n",
    "                        index_column = columns_index[j]\n",
    "\n",
    "                        row = {\n",
    "                            columns_df[j]: columns[index_column].text.strip()\n",
    "                        }\n",
    "\n",
    "                    dict_merge = {**dict_merge, **row}\n",
    "\n",
    "                df = pd.concat([df, pd.DataFrame([dict_merge])], axis = 0, ignore_index=True) \n",
    "    \n",
    "    value['df'] = df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ships =  pd.DataFrame(columns = ['Ship','Flag'])\n",
    "\n",
    "for key, value in infos_dict.items():\n",
    "\n",
    "    if 'Flag' not in infos_dict[key]['df'].columns:\n",
    "\n",
    "        infos_dict[key]['df']['Flag'] = None\n",
    "    \n",
    "    if 'IMO' not in infos_dict[key]['df'].columns:\n",
    "\n",
    "        infos_dict[key]['df']['IMO'] = None\n",
    "\n",
    "    dim_ships = pd.concat([dim_ships,pd.DataFrame(infos_dict[key]['df'].loc[:,['Ship','Flag','IMO']])], axis = 0, ignore_index=True) \n",
    "    dim_ships.drop_duplicates(subset='Ship',inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ship</th>\n",
       "      <th>Flag</th>\n",
       "      <th>IMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COSCO SHIPPING ARGENTINA</td>\n",
       "      <td>None</td>\n",
       "      <td>9945849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDUSTRIAL MOMENTUM</td>\n",
       "      <td>None</td>\n",
       "      <td>9534432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALKYONI</td>\n",
       "      <td>None</td>\n",
       "      <td>9624055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDROMEDA</td>\n",
       "      <td>None</td>\n",
       "      <td>9705110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS SABINE</td>\n",
       "      <td>None</td>\n",
       "      <td>9813802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>PERSISTENCE DIVA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>TANABATA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>PHOENIX OCEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>DESERT PIONEER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>SRAKANE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Ship  Flag      IMO\n",
       "0    COSCO SHIPPING ARGENTINA  None  9945849\n",
       "1         INDUSTRIAL MOMENTUM  None  9534432\n",
       "2                     ALKYONI  None  9624055\n",
       "3                   ANDROMEDA  None  9705110\n",
       "4                   AS SABINE  None  9813802\n",
       "..                        ...   ...      ...\n",
       "336          PERSISTENCE DIVA  None     None\n",
       "337                  TANABATA  None     None\n",
       "338             PHOENIX OCEAN  None     None\n",
       "342            DESERT PIONEER  None     None\n",
       "344                   SRAKANE  None     None\n",
       "\n",
       "[326 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates -24.0°N -46.375°E\n",
      "Elevation 6.0 m asl\n",
      "Timezone b'America/Sao_Paulo' b'-03'\n",
      "Timezone difference to GMT+0 -10800 s\n",
      "                         date  temperature_2m  relative_humidity_2m  \\\n",
      "0   2025-01-01 03:00:00+00:00       24.767000                  86.0   \n",
      "1   2025-01-01 04:00:00+00:00       24.167000                  89.0   \n",
      "2   2025-01-01 05:00:00+00:00       23.767000                  91.0   \n",
      "3   2025-01-01 06:00:00+00:00       23.717001                  91.0   \n",
      "4   2025-01-01 07:00:00+00:00       23.417000                  91.0   \n",
      "..                        ...             ...                   ...   \n",
      "211 2025-01-09 22:00:00+00:00       24.067001                  74.0   \n",
      "212 2025-01-09 23:00:00+00:00       23.817001                  77.0   \n",
      "213 2025-01-10 00:00:00+00:00       23.567001                  79.0   \n",
      "214 2025-01-10 01:00:00+00:00       23.217001                  81.0   \n",
      "215 2025-01-10 02:00:00+00:00       22.817001                  83.0   \n",
      "\n",
      "     dew_point_2m  precipitation_probability  precipitation  rain  \\\n",
      "0       22.265339                        0.0            0.0   0.0   \n",
      "1       22.238607                        0.0            0.0   0.0   \n",
      "2       22.208866                        0.0            0.0   0.0   \n",
      "3       22.159452                        0.0            0.0   0.0   \n",
      "4       21.862940                        0.0            0.0   0.0   \n",
      "..            ...                        ...            ...   ...   \n",
      "211     19.144304                       38.0            0.0   0.0   \n",
      "212     19.541542                       38.0            0.0   0.0   \n",
      "213     19.712116                       38.0            0.0   0.0   \n",
      "214     19.774677                       37.0            0.0   0.0   \n",
      "215     19.777674                       34.0            0.0   0.0   \n",
      "\n",
      "     pressure_msl  surface_pressure  visibility  evapotranspiration  \\\n",
      "0     1012.799988       1012.103455     24140.0                0.01   \n",
      "1     1012.200012       1011.502563     24140.0                0.01   \n",
      "2     1011.700012       1011.001953     24140.0                0.01   \n",
      "3     1011.900024       1011.201599     24140.0                0.01   \n",
      "4     1011.599976       1010.901001     24140.0                0.01   \n",
      "..            ...               ...         ...                 ...   \n",
      "211   1012.700012       1012.002014     17360.0                0.12   \n",
      "212   1013.000000       1012.301025     15260.0                0.09   \n",
      "213   1013.200012       1012.500305     13180.0                0.06   \n",
      "214   1013.200012       1012.499695     14480.0                0.04   \n",
      "215   1013.200012       1012.498779     15760.0                0.03   \n",
      "\n",
      "     wind_speed_80m  wind_speed_120m  wind_direction_80m  wind_direction_120m  \n",
      "0          0.360000         1.800000           90.000000            90.000000  \n",
      "1          1.018234         1.484318          315.000092           104.036270  \n",
      "2          2.099143         0.360000          300.963684            90.000000  \n",
      "3          2.545584         1.138420          278.130005           251.564957  \n",
      "4          3.240000         2.099143          270.000000           239.036301  \n",
      "..              ...              ...                 ...                  ...  \n",
      "211       12.101570        12.768586          112.751015           111.501495  \n",
      "212       12.074766        13.378250          116.564987           113.805946  \n",
      "213       10.630672        12.101570          118.300667           112.751015  \n",
      "214        6.034700         7.695920          107.354111           100.784256  \n",
      "215        3.075841         4.334974           20.556128            41.633450  \n",
      "\n",
      "[216 rows x 15 columns]\n",
      "                       date  sunrise  sunset  uv_index_max\n",
      "0 2025-01-01 03:00:00+00:00        0       0          9.25\n",
      "1 2025-01-02 03:00:00+00:00        0       0          9.35\n",
      "2 2025-01-03 03:00:00+00:00        0       0          9.45\n",
      "3 2025-01-04 03:00:00+00:00        0       0          9.20\n",
      "4 2025-01-05 03:00:00+00:00        0       0          9.30\n",
      "5 2025-01-06 03:00:00+00:00        0       0          9.20\n",
      "6 2025-01-07 03:00:00+00:00        0       0          7.00\n",
      "7 2025-01-08 03:00:00+00:00        0       0          8.40\n",
      "8 2025-01-09 03:00:00+00:00        0       0          8.40\n"
     ]
    }
   ],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "\t\"latitude\": -23.9608,\n",
    "\t\"longitude\": -46.3336,\n",
    "\t\"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation_probability\", \"precipitation\", \"rain\", \"pressure_msl\", \"surface_pressure\", \"visibility\", \"evapotranspiration\", \"wind_speed_80m\", \"wind_speed_120m\", \"wind_direction_80m\", \"wind_direction_120m\"],\n",
    "\t\"daily\": [\"sunrise\", \"sunset\", \"uv_index_max\"],\n",
    "\t\"timezone\": \"America/Sao_Paulo\",\n",
    "\t\"past_days\": 2\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_dew_point_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_precipitation_probability = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_rain = hourly.Variables(5).ValuesAsNumpy()\n",
    "hourly_pressure_msl = hourly.Variables(6).ValuesAsNumpy()\n",
    "hourly_surface_pressure = hourly.Variables(7).ValuesAsNumpy()\n",
    "hourly_visibility = hourly.Variables(8).ValuesAsNumpy()\n",
    "hourly_evapotranspiration = hourly.Variables(9).ValuesAsNumpy()\n",
    "hourly_wind_speed_80m = hourly.Variables(10).ValuesAsNumpy()\n",
    "hourly_wind_speed_120m = hourly.Variables(11).ValuesAsNumpy()\n",
    "hourly_wind_direction_80m = hourly.Variables(12).ValuesAsNumpy()\n",
    "hourly_wind_direction_120m = hourly.Variables(13).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "hourly_data[\"dew_point_2m\"] = hourly_dew_point_2m\n",
    "hourly_data[\"precipitation_probability\"] = hourly_precipitation_probability\n",
    "hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "hourly_data[\"rain\"] = hourly_rain\n",
    "hourly_data[\"pressure_msl\"] = hourly_pressure_msl\n",
    "hourly_data[\"surface_pressure\"] = hourly_surface_pressure\n",
    "hourly_data[\"visibility\"] = hourly_visibility\n",
    "hourly_data[\"evapotranspiration\"] = hourly_evapotranspiration\n",
    "hourly_data[\"wind_speed_80m\"] = hourly_wind_speed_80m\n",
    "hourly_data[\"wind_speed_120m\"] = hourly_wind_speed_120m\n",
    "hourly_data[\"wind_direction_80m\"] = hourly_wind_direction_80m\n",
    "hourly_data[\"wind_direction_120m\"] = hourly_wind_direction_120m\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "print(hourly_dataframe)\n",
    "\n",
    "# Process daily data. The order of variables needs to be the same as requested.\n",
    "daily = response.Daily()\n",
    "daily_sunrise = daily.Variables(0).ValuesAsNumpy()\n",
    "daily_sunset = daily.Variables(1).ValuesAsNumpy()\n",
    "daily_uv_index_max = daily.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "daily_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "daily_data[\"sunrise\"] = daily_sunrise\n",
    "daily_data[\"sunset\"] = daily_sunset\n",
    "daily_data[\"uv_index_max\"] = daily_uv_index_max\n",
    "\n",
    "daily_dataframe = pd.DataFrame(data = daily_data)\n",
    "print(daily_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
