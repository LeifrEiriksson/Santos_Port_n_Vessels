{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "import httpx\n",
    "from retry_requests import retry\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict = {\n",
    "'scheduled' : {\n",
    "'url': \"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/atracacoes-programadas/\",\n",
    "'columns':['Date','Hour','ETA','Place','Ship','IMO','Cargo','Event','Voyage','DUV'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'foreseen_cargo' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/navios-esperados-carga/\",\n",
    "'columns':['Ship','Flag','Draft','Nav','Arrival','Notice','Office','Operation','Goods','Weight','Voyage','DUV','P','Terminal','IMO'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'foreseen_cruise' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/navios-esperados-passageiros/\",\n",
    "'columns':['Ship','Flag','Draft','Nav','Arrival','Notice','Office','Voyage','DUV','P','Terminal'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'berthage_ships' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/navios-fundeados/\",\n",
    "'columns':['Ship','Flag','Draft','Nav','Arrival','Notice','Office','Operat','Type','Weight','Voyage','P','Terminal'],\n",
    "'df' : None\n",
    "},\n",
    "\n",
    "'berthed_ships' : {\n",
    "'url':\"https://www.portodesantos.com.br/informacoes-operacionais/operacoes-portuarias/navegacao-e-movimento-de-navios/atracados-porto-terminais/\",\n",
    "'columns':['Place','Ship','Cargo','Unload','Load'],\n",
    "'df' : None\n",
    "},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Port_and_vessels_Santos\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Port_and_vessels_Santos\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Port_and_vessels_Santos\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Port_and_vessels_Santos\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\João Vitor\\Desktop\\Projetos\\Port_and_vessels_Santos\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.portodesantos.com.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for key, value in infos_dict.items():\n",
    "\n",
    "    table = None\n",
    "    op = None\n",
    "\n",
    "    url = value['url']\n",
    "    columns_df = value['columns']\n",
    "    \n",
    "    data = requests.get(url, verify=False).text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "    if key != 'berthed_ships':\n",
    "        table = soup.find_all('tbody')\n",
    "\n",
    "    else:\n",
    "        table = soup.find('table', {'id':'atracados'})\n",
    "\n",
    "    df = pd.DataFrame(columns = columns_df)\n",
    "\n",
    "    for i in range(len(table)):\n",
    "\n",
    "        if key != 'berthed_ships':\n",
    "            op = table[i].find_all('tr')\n",
    "\n",
    "        else:\n",
    "            op = table_berthed.tbody.find_all('tr')\n",
    "\n",
    "        for row in op:\n",
    "\n",
    "            columns = row.find_all('td')\n",
    "\n",
    "            if(columns != []):\n",
    "\n",
    "                dict_merge = {}\n",
    "\n",
    "                for j in range(len(columns_df)):\n",
    "\n",
    "                    if key != 'berthed_ships':\n",
    "\n",
    "                        row = {\n",
    "                            columns_df[j]: columns[j].text.strip()\n",
    "                        }\n",
    "                    \n",
    "                    else:\n",
    "                                                \n",
    "                        columns_index = (0,1,6,7,8)\n",
    "\n",
    "                        index_column = columns_index[j]\n",
    "\n",
    "                        row = {\n",
    "                            columns_df[j]: columns[index_column].text.strip()\n",
    "                        }\n",
    "\n",
    "                    dict_merge = {**dict_merge, **row}\n",
    "\n",
    "                df = pd.concat([df, pd.DataFrame([dict_merge])], axis = 0, ignore_index=True) \n",
    "    \n",
    "    value['df'] = df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ships =  pd.DataFrame(columns = ['Ship','Flag'])\n",
    "\n",
    "for key, value in infos_dict.items():\n",
    "\n",
    "    if 'Flag' not in infos_dict[key]['df'].columns:\n",
    "\n",
    "        infos_dict[key]['df']['Flag'] = None\n",
    "    \n",
    "    if 'IMO' not in infos_dict[key]['df'].columns:\n",
    "\n",
    "        infos_dict[key]['df']['IMO'] = None\n",
    "\n",
    "    dim_ships = pd.concat([dim_ships,pd.DataFrame(infos_dict[key]['df'].loc[:,['Ship','Flag','IMO']])], axis = 0, ignore_index=True) \n",
    "    dim_ships.drop_duplicates(subset='Ship',inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ship</th>\n",
       "      <th>Flag</th>\n",
       "      <th>IMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COSCO SHIPPING ARGENTINA</td>\n",
       "      <td>None</td>\n",
       "      <td>9945849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDUSTRIAL MOMENTUM</td>\n",
       "      <td>None</td>\n",
       "      <td>9534432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALKYONI</td>\n",
       "      <td>None</td>\n",
       "      <td>9624055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANDROMEDA</td>\n",
       "      <td>None</td>\n",
       "      <td>9705110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS SABINE</td>\n",
       "      <td>None</td>\n",
       "      <td>9813802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>PERSISTENCE DIVA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>TANABATA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>PHOENIX OCEAN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>DESERT PIONEER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>SRAKANE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Ship  Flag      IMO\n",
       "0    COSCO SHIPPING ARGENTINA  None  9945849\n",
       "1         INDUSTRIAL MOMENTUM  None  9534432\n",
       "2                     ALKYONI  None  9624055\n",
       "3                   ANDROMEDA  None  9705110\n",
       "4                   AS SABINE  None  9813802\n",
       "..                        ...   ...      ...\n",
       "338          PERSISTENCE DIVA  None     None\n",
       "339                  TANABATA  None     None\n",
       "340             PHOENIX OCEAN  None     None\n",
       "343            DESERT PIONEER  None     None\n",
       "345                   SRAKANE  None     None\n",
       "\n",
       "[328 rows x 3 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates -24.0°N -46.375°E\n",
      "Elevation 6.0 m asl\n",
      "Timezone b'America/Sao_Paulo' b'-03'\n",
      "Timezone difference to GMT+0 -10800 s\n",
      "                         date  temperature_2m  relative_humidity_2m  \\\n",
      "0   2024-12-26 03:00:00+00:00       26.067001                  83.0   \n",
      "1   2024-12-26 04:00:00+00:00       25.767000                  86.0   \n",
      "2   2024-12-26 05:00:00+00:00       25.567001                  87.0   \n",
      "3   2024-12-26 06:00:00+00:00       25.217001                  92.0   \n",
      "4   2024-12-26 07:00:00+00:00       25.117001                  93.0   \n",
      "..                        ...             ...                   ...   \n",
      "211 2025-01-03 22:00:00+00:00       25.567001                  87.0   \n",
      "212 2025-01-03 23:00:00+00:00       25.217001                  88.0   \n",
      "213 2025-01-04 00:00:00+00:00       25.017000                  89.0   \n",
      "214 2025-01-04 01:00:00+00:00       25.117001                  88.0   \n",
      "215 2025-01-04 02:00:00+00:00       25.417000                  87.0   \n",
      "\n",
      "     dew_point_2m  precipitation_probability  precipitation  rain  \\\n",
      "0       22.953346                       50.0            0.1   0.0   \n",
      "1       23.246708                       65.0            0.1   0.0   \n",
      "2       23.241673                       75.0            0.1   0.1   \n",
      "3       23.823513                       78.0            0.2   0.2   \n",
      "4       23.904270                       90.0            0.4   0.4   \n",
      "..            ...                        ...            ...   ...   \n",
      "211     23.241673                       76.0            0.0   0.0   \n",
      "212     23.086525                       77.0            0.0   0.0   \n",
      "213     23.076365                       78.0            0.0   0.0   \n",
      "214     22.988106                       77.0            0.0   0.0   \n",
      "215     23.094255                       75.0            0.0   0.0   \n",
      "\n",
      "     pressure_msl  surface_pressure  visibility  evapotranspiration  \\\n",
      "0     1009.400024       1008.708984      5780.0                0.03   \n",
      "1     1008.700012       1008.008484     16340.0                0.02   \n",
      "2     1008.099976       1007.408630     16900.0                0.02   \n",
      "3     1007.299988       1006.608215     22400.0                0.02   \n",
      "4     1007.400024       1006.708191     24140.0                0.01   \n",
      "..            ...               ...         ...                 ...   \n",
      "211   1006.700012       1006.009583     24140.0                0.12   \n",
      "212   1007.200012       1006.508301     24140.0                0.07   \n",
      "213   1007.500000       1006.807739     24140.0                0.04   \n",
      "214   1007.500000       1006.808105     19400.0                0.02   \n",
      "215   1007.400024       1006.708801     14660.0                0.01   \n",
      "\n",
      "     wind_speed_80m  wind_speed_120m  wind_direction_80m  wind_direction_120m  \n",
      "0          5.315336         6.379216          331.699341           343.610382  \n",
      "1          6.214563         6.489992          259.992096           273.179779  \n",
      "2          6.989935         7.235910          258.111359           264.289490  \n",
      "3          5.804825         6.439876          240.255203           243.435013  \n",
      "4          6.638072         7.653705          220.601212           221.185822  \n",
      "..              ...              ...                 ...                  ...  \n",
      "211        7.289444         8.121970          110.224953           102.804260  \n",
      "212        6.287130         8.209263           76.759468            74.744827  \n",
      "213        6.409617         8.788720           51.842735            55.007900  \n",
      "214        5.692099         7.421590           34.695221            39.093861  \n",
      "215        4.104631         5.937272           15.255177            14.036275  \n",
      "\n",
      "[216 rows x 15 columns]\n",
      "                       date  sunrise  sunset  uv_index_max\n",
      "0 2024-12-26 03:00:00+00:00        0       0          1.85\n",
      "1 2024-12-27 03:00:00+00:00        0       0          7.40\n",
      "2 2024-12-28 03:00:00+00:00        0       0          8.50\n",
      "3 2024-12-29 03:00:00+00:00        0       0          8.60\n",
      "4 2024-12-30 03:00:00+00:00        0       0          7.70\n",
      "5 2024-12-31 03:00:00+00:00        0       0          8.65\n",
      "6 2025-01-01 03:00:00+00:00        0       0          8.75\n",
      "7 2025-01-02 03:00:00+00:00        0       0          8.80\n",
      "8 2025-01-03 03:00:00+00:00        0       0          2.35\n"
     ]
    }
   ],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "\n",
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "\t\"latitude\": -23.9608,\n",
    "\t\"longitude\": -46.3336,\n",
    "\t\"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation_probability\", \"precipitation\", \"rain\", \"pressure_msl\", \"surface_pressure\", \"visibility\", \"evapotranspiration\", \"wind_speed_80m\", \"wind_speed_120m\", \"wind_direction_80m\", \"wind_direction_120m\"],\n",
    "\t\"daily\": [\"sunrise\", \"sunset\", \"uv_index_max\"],\n",
    "\t\"timezone\": \"America/Sao_Paulo\",\n",
    "\t\"past_days\": 2\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
    "\n",
    "# Process hourly data. The order of variables needs to be the same as requested.\n",
    "hourly = response.Hourly()\n",
    "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "hourly_dew_point_2m = hourly.Variables(2).ValuesAsNumpy()\n",
    "hourly_precipitation_probability = hourly.Variables(3).ValuesAsNumpy()\n",
    "hourly_precipitation = hourly.Variables(4).ValuesAsNumpy()\n",
    "hourly_rain = hourly.Variables(5).ValuesAsNumpy()\n",
    "hourly_pressure_msl = hourly.Variables(6).ValuesAsNumpy()\n",
    "hourly_surface_pressure = hourly.Variables(7).ValuesAsNumpy()\n",
    "hourly_visibility = hourly.Variables(8).ValuesAsNumpy()\n",
    "hourly_evapotranspiration = hourly.Variables(9).ValuesAsNumpy()\n",
    "hourly_wind_speed_80m = hourly.Variables(10).ValuesAsNumpy()\n",
    "hourly_wind_speed_120m = hourly.Variables(11).ValuesAsNumpy()\n",
    "hourly_wind_direction_80m = hourly.Variables(12).ValuesAsNumpy()\n",
    "hourly_wind_direction_120m = hourly.Variables(13).ValuesAsNumpy()\n",
    "\n",
    "hourly_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "hourly_data[\"dew_point_2m\"] = hourly_dew_point_2m\n",
    "hourly_data[\"precipitation_probability\"] = hourly_precipitation_probability\n",
    "hourly_data[\"precipitation\"] = hourly_precipitation\n",
    "hourly_data[\"rain\"] = hourly_rain\n",
    "hourly_data[\"pressure_msl\"] = hourly_pressure_msl\n",
    "hourly_data[\"surface_pressure\"] = hourly_surface_pressure\n",
    "hourly_data[\"visibility\"] = hourly_visibility\n",
    "hourly_data[\"evapotranspiration\"] = hourly_evapotranspiration\n",
    "hourly_data[\"wind_speed_80m\"] = hourly_wind_speed_80m\n",
    "hourly_data[\"wind_speed_120m\"] = hourly_wind_speed_120m\n",
    "hourly_data[\"wind_direction_80m\"] = hourly_wind_direction_80m\n",
    "hourly_data[\"wind_direction_120m\"] = hourly_wind_direction_120m\n",
    "\n",
    "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "print(hourly_dataframe)\n",
    "\n",
    "# Process daily data. The order of variables needs to be the same as requested.\n",
    "daily = response.Daily()\n",
    "daily_sunrise = daily.Variables(0).ValuesAsNumpy()\n",
    "daily_sunset = daily.Variables(1).ValuesAsNumpy()\n",
    "daily_uv_index_max = daily.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "daily_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "daily_data[\"sunrise\"] = daily_sunrise\n",
    "daily_data[\"sunset\"] = daily_sunset\n",
    "daily_data[\"uv_index_max\"] = daily_uv_index_max\n",
    "\n",
    "daily_dataframe = pd.DataFrame(data = daily_data)\n",
    "print(daily_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
